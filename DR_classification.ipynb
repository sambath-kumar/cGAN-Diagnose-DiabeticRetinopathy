{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Classify Diabetic Retinopathy (DR) into five-classes:\n",
        "\n",
        "0 - No DR,\n",
        "1 - Mild,\n",
        "2 - Moderate,\n",
        "3 - Severe,\n",
        "4 - Proliferative DR"
      ],
      "metadata": {
        "id": "TtIHiwampJqm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get updated .csv file based on the filename of the folder. other rows gets deleted from the .csv file."
      ],
      "metadata": {
        "id": "Xx2ba3AZrpd3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Configuration\n",
        "csv_file_path = '/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/trainLabels19.csv'  # Path to your CSV file\n",
        "image_folder = '/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/ResizedTrain19-samples'  # Path to your image dataset\n",
        "output_csv_path = 'updated_trainLabels19.csv'  # Path for the updated CSV\n",
        "\n",
        "# Step 1: Load the CSV file\n",
        "df = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Step 2: Get list of actual image files in the dataset\n",
        "# Assuming images are in .png or .jpg format - adjust extensions if needed\n",
        "image_extensions = ('.png', '.jpg', '.jpeg')\n",
        "image_files = set()\n",
        "for file in os.listdir(image_folder):\n",
        "    if file.lower().endswith(image_extensions):\n",
        "        # Remove extension for matching with CSV\n",
        "        base_name = os.path.splitext(file)[0]\n",
        "        image_files.add(base_name)\n",
        "\n",
        "# Step 3: Filter the DataFrame to keep only rows with existing images\n",
        "filtered_df = df[df['id_code'].isin(image_files)]\n",
        "\n",
        "# Step 4: Save the filtered DataFrame to a new CSV\n",
        "filtered_df.to_csv(output_csv_path, index=False)\n",
        "\n",
        "print(f\"Original rows: {len(df)}, Filtered rows: {len(filtered_df)}\")\n",
        "print(f\"Updated CSV saved to: {output_csv_path}\")"
      ],
      "metadata": {
        "id": "fsSE9JpdXQi2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18395a1-aa71-46ed-a18f-8120bd61c367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rows: 3662, Filtered rows: 728\n",
            "Updated CSV saved to: updated_trainLabels19.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following scripts contains:\n",
        "(i) GAN-based OCT-A generation\n",
        "\n",
        "(ii) Training ResNet50Fusion model\n",
        "\n",
        "(iii) Saving the model\n",
        "\n",
        "(iv) Running inference on test data\n",
        "\n",
        "(v) Saving predictions to CSV"
      ],
      "metadata": {
        "id": "pYOzsceSjYs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "import tensorflow as tf\n",
        "\n",
        "# ----------------------------\n",
        "# Load BVAC GAN generator\n",
        "# ----------------------------\n",
        "class InstanceNormalization(tf.keras.layers.Layer):\n",
        "    def __init__(self, epsilon=1e-5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.scale = self.add_weight(name=\"scale\", shape=(input_shape[-1],), initializer=\"ones\", trainable=True)\n",
        "        self.offset = self.add_weight(name=\"offset\", shape=(input_shape[-1],), initializer=\"zeros\", trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        mean, var = tf.nn.moments(inputs, [1, 2], keepdims=True)\n",
        "        normalized = (inputs - mean) / tf.sqrt(var + self.epsilon)\n",
        "        return self.scale * normalized + self.offset\n",
        "\n",
        "class ThresholdSEBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, channels, reduction=16, threshold=0.5, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.channels = channels\n",
        "        self.reduction = reduction\n",
        "        self.threshold = threshold\n",
        "        self.global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fc1 = tf.keras.layers.Dense(channels // reduction, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(channels, activation='sigmoid')\n",
        "\n",
        "    def call(self, inputs):\n",
        "        x = self.global_avg_pool(inputs)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = tf.where(x > self.threshold, x, tf.zeros_like(x))\n",
        "        x = tf.reshape(x, [-1, 1, 1, self.channels])\n",
        "        return inputs * x\n",
        "\n",
        "generator = tf.keras.models.load_model(\n",
        "    '/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/generator_g.h5',\n",
        "    custom_objects={'InstanceNormalization': InstanceNormalization, 'ThresholdSEBlock': ThresholdSEBlock}\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# Image Pre/Post-Processing\n",
        "# ----------------------------\n",
        "def preprocess_tf(img_path):\n",
        "    img = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n",
        "    arr = np.array(img).astype(np.float32) / 127.5 - 1.0\n",
        "    return np.expand_dims(arr, 0)\n",
        "\n",
        "def postprocess_tf(tensor):\n",
        "    tensor = (tensor[0] * 0.5 + 0.5) * 255.0\n",
        "    return Image.fromarray(np.clip(tensor, 0, 255).astype(np.uint8))\n",
        "\n",
        "def generate_synthetic_oct(images_dir, synthetic_dir):\n",
        "    os.makedirs(synthetic_dir, exist_ok=True)\n",
        "    for img_name in os.listdir(images_dir):\n",
        "        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "            continue\n",
        "        img_path = os.path.join(images_dir, img_name)\n",
        "        input_tensor = preprocess_tf(img_path)\n",
        "        output_tensor = generator.predict(input_tensor)\n",
        "        output_img = postprocess_tf(output_tensor)\n",
        "        output_img.save(os.path.join(synthetic_dir, img_name))\n",
        "\n",
        "# ----------------------------\n",
        "# Dataset Classes\n",
        "# ----------------------------\n",
        "class FusedDataset(Dataset):\n",
        "    def __init__(self, csv_file, fundus_dir, synthetic_dir):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.fundus_dir = fundus_dir\n",
        "        self.synthetic_dir = synthetic_dir\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_id = row['id_code']\n",
        "        label = int(row['diagnosis'])\n",
        "        extensions = ['.jpg', '.jpeg', '.png']\n",
        "        for ext in extensions:\n",
        "            fp = os.path.join(self.fundus_dir, img_id + ext)\n",
        "            sp = os.path.join(self.synthetic_dir, img_id + ext)\n",
        "            if os.path.exists(fp) and os.path.exists(sp):\n",
        "                fundus = Image.open(fp).convert(\"RGB\")\n",
        "                synthetic = Image.open(sp).convert(\"RGB\")\n",
        "                fundus = self.transform(fundus)\n",
        "                synthetic = self.transform(synthetic)\n",
        "                fused = torch.cat((fundus, synthetic), dim=0)\n",
        "                return fused, label\n",
        "        raise FileNotFoundError(f\"{img_id} not found.\")\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, csv_file, fundus_dir, synthetic_dir):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.fundus_dir = fundus_dir\n",
        "        self.synthetic_dir = synthetic_dir\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.data.iloc[idx]\n",
        "        img_id = row['id_code']\n",
        "        extensions = ['.jpg', '.jpeg', '.png']\n",
        "        for ext in extensions:\n",
        "            fp = os.path.join(self.fundus_dir, img_id + ext)\n",
        "            sp = os.path.join(self.synthetic_dir, img_id + ext)\n",
        "            if os.path.exists(fp) and os.path.exists(sp):\n",
        "                fundus = Image.open(fp).convert(\"RGB\")\n",
        "                synthetic = Image.open(sp).convert(\"RGB\")\n",
        "                fundus = self.transform(fundus)\n",
        "                synthetic = self.transform(synthetic)\n",
        "                fused = torch.cat((fundus, synthetic), dim=0)\n",
        "                return fused, img_id\n",
        "        raise FileNotFoundError(f\"{img_id} not found.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Model Definition\n",
        "# ----------------------------\n",
        "class ResNet50Fusion(nn.Module):\n",
        "    def __init__(self, num_classes=5):\n",
        "        super().__init__()\n",
        "        base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        self.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.conv1.weight.data[:, :3] = base.conv1.weight.data\n",
        "        self.conv1.weight.data[:, 3:] = base.conv1.weight.data.clone()\n",
        "        base.conv1 = self.conv1\n",
        "        base.fc = nn.Linear(2048, num_classes)\n",
        "        self.model = base\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# ----------------------------\n",
        "# Training Function\n",
        "# ----------------------------\n",
        "def train_model():\n",
        "    fundus_dir = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/ResizedTrain19-samples\"\n",
        "    synthetic_dir = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/synthetic_octa\"\n",
        "    csv_file = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/updated_trainLabels19.csv\"\n",
        "\n",
        "    generate_synthetic_oct(fundus_dir, synthetic_dir)\n",
        "\n",
        "    dataset = FusedDataset(csv_file, fundus_dir, synthetic_dir)\n",
        "    loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = ResNet50Fusion(num_classes=5).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss, correct = 0, 0\n",
        "        for inputs, labels in loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).sum().item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Acc: {correct/len(dataset):.4f}\")\n",
        "\n",
        "    torch.save(model.state_dict(), \"resnet50_fused_model.pth\")\n",
        "    print(\"Model saved.\")\n",
        "\n",
        "# ----------------------------\n",
        "# Inference Function\n",
        "# ----------------------------\n",
        "def predict(model, dataloader, device):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, img_ids in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
        "            for img_id, pred in zip(img_ids, preds):\n",
        "                results.append((img_id, pred))\n",
        "    return results\n",
        "\n",
        "def run_inference():\n",
        "    test_csv = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/trainLabels19_test.csv\"\n",
        "    fundus_dir = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/ResizedTrain19_test\"\n",
        "    synthetic_dir = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/synthetic_test_octa\"\n",
        "\n",
        "    generate_synthetic_oct(fundus_dir, synthetic_dir)\n",
        "\n",
        "    test_dataset = TestDataset(test_csv, fundus_dir, synthetic_dir)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = ResNet50Fusion(num_classes=5).to(device)\n",
        "    model.load_state_dict(torch.load(\"resnet50_fused_model.pth\"))\n",
        "\n",
        "    predictions = predict(model, test_loader, device)\n",
        "    pd.DataFrame(predictions, columns=[\"id_code\", \"predicted_label\"]).to_csv(\"DR_predictions.csv\", index=False)\n",
        "    print(\"Predictions saved to DR_predictions.csv\")\n",
        "\n",
        "# ----------------------------\n",
        "# Run Training and Inference\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()\n",
        "    run_inference()\n"
      ],
      "metadata": {
        "id": "lRy_xu-Sj3Mw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}