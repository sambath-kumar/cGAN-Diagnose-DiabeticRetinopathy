{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1wSMz77C3yuGQwGDLt1Oh4Up6k1ddfI-Z","authorship_tag":"ABX9TyMmboYVNptkJwAEMSOVhDsX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Classify Diabetic Retinopathy (DR) into five-classes:\n","\n","0 - No DR,\n","1 - Mild,\n","2 - Moderate,\n","3 - Severe,\n","4 - Proliferative DR"],"metadata":{"id":"TtIHiwampJqm"}},{"cell_type":"markdown","source":["To get updated .csv file based on the filename of the folder. other rows gets deleted from the .csv file."],"metadata":{"id":"Xx2ba3AZrpd3"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","\n","# Configuration\n","csv_file_path = '/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/trainLabels19.csv'  # Path to your CSV file\n","image_folder = '/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/ResizedTrain19-samples'  # Path to your image dataset\n","output_csv_path = 'updated_trainLabels19.csv'  # Path for the updated CSV\n","\n","# Step 1: Load the CSV file\n","df = pd.read_csv(csv_file_path)\n","\n","# Step 2: Get list of actual image files in the dataset\n","# Assuming images are in .png or .jpg format - adjust extensions if needed\n","image_extensions = ('.png', '.jpg', '.jpeg')\n","image_files = set()\n","for file in os.listdir(image_folder):\n","    if file.lower().endswith(image_extensions):\n","        # Remove extension for matching with CSV\n","        base_name = os.path.splitext(file)[0]\n","        image_files.add(base_name)\n","\n","# Step 3: Filter the DataFrame to keep only rows with existing images\n","filtered_df = df[df['id_code'].isin(image_files)]\n","\n","# Step 4: Save the filtered DataFrame to a new CSV\n","filtered_df.to_csv(output_csv_path, index=False)\n","\n","print(f\"Original rows: {len(df)}, Filtered rows: {len(filtered_df)}\")\n","print(f\"Updated CSV saved to: {output_csv_path}\")"],"metadata":{"id":"fsSE9JpdXQi2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1746787700940,"user_tz":-330,"elapsed":933,"user":{"displayName":"sambath kumar","userId":"14872186085352734726"}},"outputId":"f18395a1-aa71-46ed-a18f-8120bd61c367"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original rows: 3662, Filtered rows: 728\n","Updated CSV saved to: updated_trainLabels19.csv\n"]}]},{"cell_type":"markdown","source":["The following scripts contains:\n","(i) GAN-based OCT-A generation\n","\n","(ii) Training ResNet50Fusion model\n","\n","(iii) Saving the model\n","\n","(iv) Running inference on test data\n","\n","(v) Saving predictions to CSV"],"metadata":{"id":"pYOzsceSjYs4"}},{"cell_type":"code","source":["import os\n","import pandas as pd\n","from PIL import Image\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import models, transforms\n","import tensorflow as tf\n","\n","# ----------------------------\n","# Load BVAC GAN generator\n","# ----------------------------\n","class InstanceNormalization(tf.keras.layers.Layer):\n","    def __init__(self, epsilon=1e-5, **kwargs):\n","        super().__init__(**kwargs)\n","        self.epsilon = epsilon\n","\n","    def build(self, input_shape):\n","        self.scale = self.add_weight(name=\"scale\", shape=(input_shape[-1],), initializer=\"ones\", trainable=True)\n","        self.offset = self.add_weight(name=\"offset\", shape=(input_shape[-1],), initializer=\"zeros\", trainable=True)\n","\n","    def call(self, inputs):\n","        mean, var = tf.nn.moments(inputs, [1, 2], keepdims=True)\n","        normalized = (inputs - mean) / tf.sqrt(var + self.epsilon)\n","        return self.scale * normalized + self.offset\n","\n","class ThresholdSEBlock(tf.keras.layers.Layer):\n","    def __init__(self, channels, reduction=16, threshold=0.5, **kwargs):\n","        super().__init__(**kwargs)\n","        self.channels = channels\n","        self.reduction = reduction\n","        self.threshold = threshold\n","        self.global_avg_pool = tf.keras.layers.GlobalAveragePooling2D()\n","        self.fc1 = tf.keras.layers.Dense(channels // reduction, activation='relu')\n","        self.fc2 = tf.keras.layers.Dense(channels, activation='sigmoid')\n","\n","    def call(self, inputs):\n","        x = self.global_avg_pool(inputs)\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        x = tf.where(x > self.threshold, x, tf.zeros_like(x))\n","        x = tf.reshape(x, [-1, 1, 1, self.channels])\n","        return inputs * x\n","\n","generator = tf.keras.models.load_model(\n","    '/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/generator_g.h5',\n","    custom_objects={'InstanceNormalization': InstanceNormalization, 'ThresholdSEBlock': ThresholdSEBlock}\n",")\n","\n","# ----------------------------\n","# Image Pre/Post-Processing\n","# ----------------------------\n","def preprocess_tf(img_path):\n","    img = Image.open(img_path).convert(\"RGB\").resize((256, 256))\n","    arr = np.array(img).astype(np.float32) / 127.5 - 1.0\n","    return np.expand_dims(arr, 0)\n","\n","def postprocess_tf(tensor):\n","    tensor = (tensor[0] * 0.5 + 0.5) * 255.0\n","    return Image.fromarray(np.clip(tensor, 0, 255).astype(np.uint8))\n","\n","def generate_synthetic_oct(images_dir, synthetic_dir):\n","    os.makedirs(synthetic_dir, exist_ok=True)\n","    for img_name in os.listdir(images_dir):\n","        if not img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n","            continue\n","        img_path = os.path.join(images_dir, img_name)\n","        input_tensor = preprocess_tf(img_path)\n","        output_tensor = generator.predict(input_tensor)\n","        output_img = postprocess_tf(output_tensor)\n","        output_img.save(os.path.join(synthetic_dir, img_name))\n","\n","# ----------------------------\n","# Dataset Classes\n","# ----------------------------\n","class FusedDataset(Dataset):\n","    def __init__(self, csv_file, fundus_dir, synthetic_dir):\n","        self.data = pd.read_csv(csv_file)\n","        self.fundus_dir = fundus_dir\n","        self.synthetic_dir = synthetic_dir\n","        self.transform = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        img_id = row['id_code']\n","        label = int(row['diagnosis'])\n","        extensions = ['.jpg', '.jpeg', '.png']\n","        for ext in extensions:\n","            fp = os.path.join(self.fundus_dir, img_id + ext)\n","            sp = os.path.join(self.synthetic_dir, img_id + ext)\n","            if os.path.exists(fp) and os.path.exists(sp):\n","                fundus = Image.open(fp).convert(\"RGB\")\n","                synthetic = Image.open(sp).convert(\"RGB\")\n","                fundus = self.transform(fundus)\n","                synthetic = self.transform(synthetic)\n","                fused = torch.cat((fundus, synthetic), dim=0)\n","                return fused, label\n","        raise FileNotFoundError(f\"{img_id} not found.\")\n","\n","class TestDataset(Dataset):\n","    def __init__(self, csv_file, fundus_dir, synthetic_dir):\n","        self.data = pd.read_csv(csv_file)\n","        self.fundus_dir = fundus_dir\n","        self.synthetic_dir = synthetic_dir\n","        self.transform = transforms.Compose([\n","            transforms.Resize((224, 224)),\n","            transforms.ToTensor(),\n","            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","        ])\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        row = self.data.iloc[idx]\n","        img_id = row['id_code']\n","        extensions = ['.jpg', '.jpeg', '.png']\n","        for ext in extensions:\n","            fp = os.path.join(self.fundus_dir, img_id + ext)\n","            sp = os.path.join(self.synthetic_dir, img_id + ext)\n","            if os.path.exists(fp) and os.path.exists(sp):\n","                fundus = Image.open(fp).convert(\"RGB\")\n","                synthetic = Image.open(sp).convert(\"RGB\")\n","                fundus = self.transform(fundus)\n","                synthetic = self.transform(synthetic)\n","                fused = torch.cat((fundus, synthetic), dim=0)\n","                return fused, img_id\n","        raise FileNotFoundError(f\"{img_id} not found.\")\n","\n","# ----------------------------\n","# Model Definition\n","# ----------------------------\n","class ResNet50Fusion(nn.Module):\n","    def __init__(self, num_classes=5):\n","        super().__init__()\n","        base = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n","        self.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.conv1.weight.data[:, :3] = base.conv1.weight.data\n","        self.conv1.weight.data[:, 3:] = base.conv1.weight.data.clone()\n","        base.conv1 = self.conv1\n","        base.fc = nn.Linear(2048, num_classes)\n","        self.model = base\n","\n","    def forward(self, x):\n","        return self.model(x)\n","\n","# ----------------------------\n","# Training Function\n","# ----------------------------\n","def train_model():\n","    fundus_dir = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/ResizedTrain19-samples\"\n","    synthetic_dir = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/synthetic_octa\"\n","    csv_file = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/updated_trainLabels19.csv\"\n","\n","    generate_synthetic_oct(fundus_dir, synthetic_dir)\n","\n","    dataset = FusedDataset(csv_file, fundus_dir, synthetic_dir)\n","    loader = DataLoader(dataset, batch_size=16, shuffle=True)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = ResNet50Fusion(num_classes=5).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    for epoch in range(10):\n","        model.train()\n","        total_loss, correct = 0, 0\n","        for inputs, labels in loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            total_loss += loss.item()\n","            correct += (outputs.argmax(1) == labels).sum().item()\n","        print(f\"Epoch {epoch+1}, Loss: {total_loss:.4f}, Acc: {correct/len(dataset):.4f}\")\n","\n","    torch.save(model.state_dict(), \"resnet50_fused_model.pth\")\n","    print(\"Model saved.\")\n","\n","# ----------------------------\n","# Inference Function\n","# ----------------------------\n","def predict(model, dataloader, device):\n","    model.eval()\n","    results = []\n","    with torch.no_grad():\n","        for inputs, img_ids in dataloader:\n","            inputs = inputs.to(device)\n","            outputs = model(inputs)\n","            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n","            for img_id, pred in zip(img_ids, preds):\n","                results.append((img_id, pred))\n","    return results\n","\n","def run_inference():\n","    test_csv = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/trainLabels19_test.csv\"\n","    fundus_dir = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/ResizedTrain19_test\"\n","    synthetic_dir = \"/content/drive/MyDrive/Colab Notebooks/Fundus_OCTA_GAN/synthetic_test_octa\"\n","\n","    generate_synthetic_oct(fundus_dir, synthetic_dir)\n","\n","    test_dataset = TestDataset(test_csv, fundus_dir, synthetic_dir)\n","    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model = ResNet50Fusion(num_classes=5).to(device)\n","    model.load_state_dict(torch.load(\"resnet50_fused_model.pth\"))\n","\n","    predictions = predict(model, test_loader, device)\n","    pd.DataFrame(predictions, columns=[\"id_code\", \"predicted_label\"]).to_csv(\"DR_predictions.csv\", index=False)\n","    print(\"Predictions saved to DR_predictions.csv\")\n","\n","# ----------------------------\n","# Run Training and Inference\n","# ----------------------------\n","if __name__ == \"__main__\":\n","    train_model()\n","    run_inference()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lRy_xu-Sj3Mw","executionInfo":{"status":"ok","timestamp":1746854346047,"user_tz":-330,"elapsed":169435,"user":{"displayName":"sambath kumar","userId":"14872186085352734726"}},"outputId":"c2eb0a0a-d14e-4c93-8f31-ffffb2895bc6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 657ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 883ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 934ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 681ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 662ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 669ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 683ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 653ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 630ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 631ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 627ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 609ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 825ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 647ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 650ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 620ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 634ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 626ms/step\n","Epoch 1, Loss: 3.1618, Acc: 0.2000\n","Epoch 2, Loss: 2.6463, Acc: 1.0000\n","Epoch 3, Loss: 1.8999, Acc: 1.0000\n","Epoch 4, Loss: 1.5816, Acc: 1.0000\n","Epoch 5, Loss: 1.0341, Acc: 1.0000\n","Epoch 6, Loss: 0.7869, Acc: 1.0000\n","Epoch 7, Loss: 0.6031, Acc: 1.0000\n","Epoch 8, Loss: 0.3834, Acc: 1.0000\n","Epoch 9, Loss: 0.2721, Acc: 1.0000\n","Epoch 10, Loss: 0.1910, Acc: 1.0000\n","Model saved.\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 632ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 642ms/step\n","Predictions saved to DR_predictions.csv\n"]}]}]}